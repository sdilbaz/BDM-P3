{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import Row\n",
    "from pyspark.sql.types import IntegerType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.getOrCreate()\n",
    "#specifying the data path\n",
    "data_path = '/Users/hamidsakhi/git/BDM-P3/'\n",
    "\n",
    "\n",
    "purchase_file_path = data_path + 'purchase.csv'\n",
    "purchase_df = spark.read.format('csv').option('header','false').load(purchase_file_path)\n",
    "#since the dataset doesn't have column names we should add headers here\n",
    "purchase_df = purchase_df.withColumnRenamed('_c0','TransId')\\\n",
    "                               .withColumnRenamed('_c1','CustId')\\\n",
    "                               .withColumnRenamed('_c2','TransTotal')\\\n",
    "                               .withColumnRenamed('_c3','TransNumItem')\\\n",
    "                               .withColumnRenamed('_c4','TransDesc')\n",
    "purchase_df.createOrReplaceTempView('purchase')\n",
    "\n",
    "customer_file_path = data_path + 'customer.csv'\n",
    "customer_df = spark.read.format('csv').option('header','false').load(customer_file_path)\n",
    "#since the dataset doesn't have column names we should add headers here\n",
    "customer_df = customer_df.withColumnRenamed('_c0','ID')\\\n",
    "                               .withColumnRenamed('_c1','Name')\\\n",
    "                               .withColumnRenamed('_c2','Age')\\\n",
    "                               .withColumnRenamed('_c3','CountryCode')\\\n",
    "                               .withColumnRenamed('_c4','Salary')\n",
    "#creating the view \n",
    "customer_df.createOrReplaceTempView('customer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "T1 = spark.sql(\"\"\"SELECT * FROM purchase where transtotal>600\"\"\")\n",
    "\n",
    "purchase_df.createOrReplaceTempView('T1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "T2 = spark.sql(\"\"\" SELECT AVG(TransTotal) as Mean, MIN(TransTotal) As Min, Max(TransTotal) As Max \n",
    "                    FROM T1\n",
    "                    GROUP BY TransNumitem\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+-----+------+\n",
      "|              Mean|  Min|   Max|\n",
      "+------------------+-----+------+\n",
      "|1004.8838597354422| 10.0|999.99|\n",
      "|1004.5357413229322| 10.0|999.99|\n",
      "|1004.0483739908203| 10.0|999.99|\n",
      "|1004.8273086510765| 10.0|999.99|\n",
      "| 1004.497867026794|10.03|999.99|\n",
      "|1004.5615556615148|10.01|999.99|\n",
      "|1005.7739147978656|10.01|999.99|\n",
      "|1004.8441406029958| 10.0|999.99|\n",
      "|1004.9988513081908| 10.0|999.97|\n",
      "|1004.5041289494897|10.01|999.99|\n",
      "|1005.1305228108343| 10.0|999.99|\n",
      "|1004.8712438917504| 10.0|999.99|\n",
      "|1006.6067367065345|10.01|999.99|\n",
      "|1006.5836723757462| 10.0|999.99|\n",
      "|1004.6530546314438| 10.0|999.98|\n",
      "+------------------+-----+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# reporting back\n",
    "T2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#T3: Over T1, group the Purchases from P by customer ID for young customers between 18 and 25 years of age,\n",
    "# and for each group report the customer ID, their age, and total number of items that this person has \n",
    "# purchased and total amount spent by the customer.\n",
    "T3 = spark.sql(\"\"\" SELECT p.custid, sum(p.TransTotal) as total_trans, sum(TransNumItem) as total_item, Max(c.age) as age FROM T1 p, customer c \n",
    "                    where p.custid = c.id\n",
    "                    and c.age between 18 and 25\n",
    "                    group by p.custid\n",
    "                    \"\"\").createOrReplaceTempView('T3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------------------+----------+---+\n",
      "|custid|       total_trans|total_item|age|\n",
      "+------+------------------+----------+---+\n",
      "|  1159|100291.56999999999|     767.0| 18|\n",
      "| 14887|116478.49000000002|    1007.0| 23|\n",
      "| 14899|          91923.72|     770.0| 19|\n",
      "|  1572|         106420.94|     900.0| 18|\n",
      "| 16576|107532.04000000001|     881.0| 22|\n",
      "| 17427|           99807.6|     870.0| 20|\n",
      "| 18726| 81637.35999999999|     693.0| 19|\n",
      "| 19132|          105694.1|     914.0| 20|\n",
      "| 20512|          91074.28|     788.0| 21|\n",
      "| 25969|         123332.88|     896.0| 24|\n",
      "| 28316|          89832.11|     763.0| 23|\n",
      "| 29539|         109549.57|     752.0| 18|\n",
      "| 29573| 86866.79999999999|     651.0| 19|\n",
      "| 30923| 89413.56999999999|     785.0| 21|\n",
      "| 31518|103611.19000000002|     820.0| 21|\n",
      "| 31713|         105562.56|     910.0| 22|\n",
      "| 33783| 98924.45999999999|     835.0| 20|\n",
      "| 35844|          89431.42|     774.0| 20|\n",
      "| 36526|         101558.87|     851.0| 18|\n",
      "| 40874|          93614.41|     785.0| 25|\n",
      "+------+------------------+----------+---+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Show_T3 = spark.sql(\"select * from T3\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "#T4: Select all customer pairs IDs (C1 and C2) from T3 where C1 is younger in age than \n",
    "# customer C2 but C1 spent in total more money than C2 but bought less items.\n",
    "\n",
    "T4 = spark.sql(\"\"\"SELECT a.custid as C1, b.custid as C2, a.age as Age1, b.age as Age2,\n",
    "                round(a.total_trans,2) as Amount1, round(b.total_trans,2) as Amount2, \n",
    "                a.total_item as TotalItemCount1, b.total_item as TotalItemCount2 \n",
    "                FROM T3 a, T3 b\n",
    "                where a.age<b.age and\n",
    "                a.total_trans > b.total_trans\"\"\").createOrReplaceTempView('T4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----+----+----+---------+---------+---------------+---------------+\n",
      "|   C1|   C2|Age1|Age2|  Amount1|  Amount2|TotalItemCount1|TotalItemCount2|\n",
      "+-----+-----+----+----+---------+---------+---------------+---------------+\n",
      "| 1159|14899|  18|  19|100291.57| 91923.72|          767.0|          770.0|\n",
      "| 1159|17427|  18|  20|100291.57|  99807.6|          767.0|          870.0|\n",
      "| 1159|18726|  18|  19|100291.57| 81637.36|          767.0|          693.0|\n",
      "| 1159|20512|  18|  21|100291.57| 91074.28|          767.0|          788.0|\n",
      "| 1159|28316|  18|  23|100291.57| 89832.11|          767.0|          763.0|\n",
      "| 1159|29573|  18|  19|100291.57|  86866.8|          767.0|          651.0|\n",
      "| 1159|30923|  18|  21|100291.57| 89413.57|          767.0|          785.0|\n",
      "| 1159|33783|  18|  20|100291.57| 98924.46|          767.0|          835.0|\n",
      "| 1159|35844|  18|  20|100291.57| 89431.42|          767.0|          774.0|\n",
      "| 1159|40874|  18|  25|100291.57| 93614.41|          767.0|          785.0|\n",
      "| 1159|41785|  18|  19|100291.57| 97821.89|          767.0|          729.0|\n",
      "| 1159|46534|  18|  23|100291.57| 78732.31|          767.0|          696.0|\n",
      "| 1159| 6194|  18|  19|100291.57| 95655.62|          767.0|          679.0|\n",
      "|14887|40874|  23|  25|116478.49| 93614.41|         1007.0|          785.0|\n",
      "|14887|43462|  23|  24|116478.49|113212.26|         1007.0|          794.0|\n",
      "|14899|20512|  19|  21| 91923.72| 91074.28|          770.0|          788.0|\n",
      "|14899|28316|  19|  23| 91923.72| 89832.11|          770.0|          763.0|\n",
      "|14899|30923|  19|  21| 91923.72| 89413.57|          770.0|          785.0|\n",
      "|14899|35844|  19|  20| 91923.72| 89431.42|          770.0|          774.0|\n",
      "|14899|46534|  19|  23| 91923.72| 78732.31|          770.0|          696.0|\n",
      "+-----+-----+----+----+---------+---------+---------------+---------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Report back T4 in the form (C1 ID, C2 ID, Age1, Age2, TotalAmount1, TotalAmount2, TotalItemCount1,TotalItemCount2) to the client side\n",
    "T5 = spark.sql(\"select * from T4\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
